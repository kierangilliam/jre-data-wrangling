{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data\n",
    "Saves non-video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:18:36.735568Z",
     "start_time": "2020-11-27T20:18:36.509643Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T19:26:58.918768Z",
     "start_time": "2020-12-02T19:26:57.010538Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "import google_auth_oauthlib.flow\n",
    "from googleapiclient.discovery import build\n",
    "import googleapiclient.errors\n",
    "from pprint import pprint\n",
    "import json\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from tqdm import tqdm\n",
    "import youtube_dl\n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from lib.Episode import Episode, EpisodeFactory\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T19:26:59.515478Z",
     "start_time": "2020-12-02T19:26:59.511824Z"
    }
   },
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyDVxHE-OCeVAFC2AUx8GWo63P5QtHPvngQ\"\n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "BASE = \"../data/jre\"\n",
    "UPLOADS = BASE + \"/uploads.json\"\n",
    "STATS = BASE + \"/stats.json\"\n",
    "COMMENTS = BASE + \"/comments.json\"\n",
    "CAPTIONS = BASE + \"/captions.json\"\n",
    "CAPTIONS_FAILED = BASE + \"/captions_failure.json\"\n",
    "\n",
    "VIDEOS_LOCATION = \"/Volumes/JRE/jre-bucket/jre/videos/\"\n",
    "\n",
    "WEBSITE = \"../../jre-vis/public/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T07:08:19.361933Z",
     "start_time": "2020-11-30T07:08:19.034715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Disable OAuthlib's HTTPS verification when running locally.\n",
    "# *DO NOT* leave this option enabled in production.\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "# https://developers.google.com/resources/api-libraries/documentation/youtube/v3/python/latest/\n",
    "youtube = build(api_service_name, api_version, developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T07:08:42.266022Z",
     "start_time": "2020-11-30T07:08:33.353463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450/2462 -> CJITEAA\r"
     ]
    }
   ],
   "source": [
    "### Get uploads\n",
    "# request = youtube.channels().list(\n",
    "#     # part=\"snippet,contentDetails,statistics,uploads\",\n",
    "#     part=\"contentDetails\",\n",
    "#     forUsername=\"PowerfulJRE\"\n",
    "# )\n",
    "\n",
    "def get_video_ids(upload_id):\n",
    "    page_token = None\n",
    "    items = []\n",
    "    total_results = 0\n",
    "\n",
    "    while True:\n",
    "        print(f\"{len(items)}/{total_results} -> {page_token}\", end=\"\\r\")\n",
    "\n",
    "        request = youtube.playlistItems().list(\n",
    "            part=\"id,contentDetails\",\n",
    "            playlistId=upload_id,\n",
    "            pageToken=page_token,\n",
    "            maxResults=50,\n",
    "        )\n",
    "        response = request.execute()\n",
    "        items.extend([item[\"contentDetails\"][\"videoId\"] for item in response[\"items\"]])\n",
    "\n",
    "        total_results = response[\"pageInfo\"][\"totalResults\"]\n",
    "\n",
    "        if \"nextPageToken\" in response:\n",
    "            page_token = response[\"nextPageToken\"]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return items\n",
    "\n",
    "try:\n",
    "    video_ids = get_video_ids(\"UUzQUP1qoWDoEbmsQxvdjxgQ\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T07:08:42.281260Z",
     "start_time": "2020-11-30T07:08:42.268509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2462"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T07:14:28.267444Z",
     "start_time": "2020-11-30T07:08:42.286782Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2462/2462 [05:45<00:00,  7.12it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_uploads():\n",
    "    uploads = []\n",
    "    \n",
    "    for id in tqdm(video_ids): \n",
    "        response = youtube.videos().list(\n",
    "            id=id,\n",
    "            part=\"contentDetails,id,liveStreamingDetails,recordingDetails,snippet,statistics,topicDetails,status\",\n",
    "        ).execute()\n",
    "        \n",
    "        # Sanity check to ensure all responses have length 1\n",
    "        if len(response['items']) != 1:\n",
    "            print(\"There should not be more than one item for\", id)\n",
    "        \n",
    "        uploads.append(response['items'][0])\n",
    "        \n",
    "    return uploads\n",
    "\n",
    "uploads = get_uploads()\n",
    "with open(UPLOADS, \"w\") as f:\n",
    "    f.write(json.dumps(uploads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T19:27:10.582625Z",
     "start_time": "2020-12-02T19:27:10.495019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2462,\n",
       " {'kind': 'youtube#video',\n",
       "  'etag': '8fQfYHRj-LFIlJaSPrpw_E_tvnw',\n",
       "  'id': 'OaTKaHKCAFg',\n",
       "  'snippet': {'publishedAt': '2020-10-30T17:00:13Z',\n",
       "   'channelId': 'UCzQUP1qoWDoEbmsQxvdjxgQ',\n",
       "   'title': 'Joe Rogan Experience #1558 - Tristan Harris',\n",
       "   'description': 'Called the “closest thing Silicon Valley has to a conscience,” by The Atlantic magazine, Tristan Harris spent three years as a Google Design Ethicist developing a framework for how technology should “ethically” steer the thoughts and actions of billions of people from screens. He is now co-founder & president of the Center for Humane Technology, whose mission is to reverse ‘human downgrading’ and re-align technology with humanity. Additionally, he is co-host of the Center for Humane Technology’s Your Undivided Attention podcast with co-founder Aza Raskin.',\n",
       "   'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/OaTKaHKCAFg/default.jpg',\n",
       "     'width': 120,\n",
       "     'height': 90},\n",
       "    'medium': {'url': 'https://i.ytimg.com/vi/OaTKaHKCAFg/mqdefault.jpg',\n",
       "     'width': 320,\n",
       "     'height': 180},\n",
       "    'high': {'url': 'https://i.ytimg.com/vi/OaTKaHKCAFg/hqdefault.jpg',\n",
       "     'width': 480,\n",
       "     'height': 360},\n",
       "    'standard': {'url': 'https://i.ytimg.com/vi/OaTKaHKCAFg/sddefault.jpg',\n",
       "     'width': 640,\n",
       "     'height': 480}},\n",
       "   'channelTitle': 'PowerfulJRE',\n",
       "   'tags': ['Joe Rogan Experience',\n",
       "    'JRE',\n",
       "    'Joe',\n",
       "    'Rogan',\n",
       "    'podcast',\n",
       "    'MMA',\n",
       "    'comedy',\n",
       "    'stand',\n",
       "    'up',\n",
       "    'funny',\n",
       "    'Freak',\n",
       "    'Party',\n",
       "    'Joe Rogan',\n",
       "    'Tristan Harris',\n",
       "    'The Social Dilemma',\n",
       "    'JRE #1558',\n",
       "    'comedian',\n",
       "    'Facebook',\n",
       "    'Twitter',\n",
       "    'Instagram',\n",
       "    'Google',\n",
       "    'Apple',\n",
       "    'Android',\n",
       "    'iPhone'],\n",
       "   'categoryId': '22',\n",
       "   'liveBroadcastContent': 'none',\n",
       "   'defaultLanguage': 'en',\n",
       "   'localized': {'title': 'Joe Rogan Experience #1558 - Tristan Harris',\n",
       "    'description': 'Called the “closest thing Silicon Valley has to a conscience,” by The Atlantic magazine, Tristan Harris spent three years as a Google Design Ethicist developing a framework for how technology should “ethically” steer the thoughts and actions of billions of people from screens. He is now co-founder & president of the Center for Humane Technology, whose mission is to reverse ‘human downgrading’ and re-align technology with humanity. Additionally, he is co-host of the Center for Humane Technology’s Your Undivided Attention podcast with co-founder Aza Raskin.'},\n",
       "   'defaultAudioLanguage': 'en-US'},\n",
       "  'contentDetails': {'duration': 'PT2H21M33S',\n",
       "   'dimension': '2d',\n",
       "   'definition': 'hd',\n",
       "   'caption': 'false',\n",
       "   'licensedContent': True,\n",
       "   'contentRating': {},\n",
       "   'projection': 'rectangular'},\n",
       "  'status': {'uploadStatus': 'processed',\n",
       "   'privacyStatus': 'public',\n",
       "   'license': 'youtube',\n",
       "   'embeddable': True,\n",
       "   'publicStatsViewable': False,\n",
       "   'madeForKids': False},\n",
       "  'statistics': {'viewCount': '6048529',\n",
       "   'likeCount': '61347',\n",
       "   'dislikeCount': '4742',\n",
       "   'favoriteCount': '0',\n",
       "   'commentCount': '13617'},\n",
       "  'recordingDetails': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(UPLOADS, \"r\") as f:\n",
    "    uploads = json.load(f)\n",
    "# Contents of uploads\n",
    "len(uploads), uploads[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T19:22:36.915903Z",
     "start_time": "2020-11-27T19:13:04.956797Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2462/2462 [09:22<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 3 items\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/jre/captions_failure.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0600c5bd246d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCAPTIONS_FAILED\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_to_get_captions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/jre/captions_failure.json'"
     ]
    }
   ],
   "source": [
    "def get_captions():\n",
    "    failed_to_get_captions = []\n",
    "    with open(CAPTIONS, \"r\") as f:\n",
    "        captions = json.loads(f.read())\n",
    "    with open(UPLOADS, \"r\") as f:\n",
    "        uploads = json.loads(f.read())\n",
    "    \n",
    "    downloaded = 0\n",
    "    for upload in tqdm(uploads):\n",
    "        id = upload[\"id\"]\n",
    "\n",
    "        if id in captions:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            caption = YouTubeTranscriptApi.get_transcript(id)\n",
    "            captions[id] = caption\n",
    "            downloaded += 1\n",
    "        except:\n",
    "            failed_to_get_captions.append(id)\n",
    "\n",
    "        # save progress\n",
    "        if downloaded % 10 == 0:\n",
    "            with open(CAPTIONS, \"w\") as f:\n",
    "                f.write(json.dumps(captions))\n",
    "\n",
    "    print(\"Downloaded\", downloaded, \"items\")\n",
    "    return captions, failed_to_get_captions\n",
    "\n",
    "captions, failed_to_get_captions = get_captions()\n",
    "\n",
    "with open(CAPTIONS, \"w\") as f:\n",
    "    f.write(json.dumps(captions))\n",
    "\n",
    "with open(CAPTIONS_FAILED, \"w\") as f:\n",
    "    f.write(json.dumps(failed_to_get_captions))\n",
    "    \n",
    "print(len(captions.items()), len(failed_to_get_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:33:26.413318Z",
     "start_time": "2020-11-30T08:33:25.745513Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'captions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7603e9a5edf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_to_get_captions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing the following items\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'snippet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contentDetails'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'duration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploads\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_to_get_captions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'captions' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(captions.items()), len(failed_to_get_captions))\n",
    "\n",
    "print(\"Missing the following items\")\n",
    "[[(u['snippet']['title'], u['contentDetails']['duration']) for u in uploads if u['id'] == id][0] for id in failed_to_get_captions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Episodes cache\n",
    "Create episode object (lib/Episode) out of each upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:33:48.891041Z",
     "start_time": "2020-11-30T08:33:31.127416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new pickle ./jre-episodes.pickle...\n",
      "Number of loaded episodes: 2462\n"
     ]
    }
   ],
   "source": [
    "CACHE_ALL = \"./jre-episodes.pickle\"\n",
    "CACHE_SMALL = \"./jre-episodes-small.pickle\"\n",
    "CACHE = CACHE_ALL\n",
    "\n",
    "print(f\"Generating new pickle {CACHE}...\")\n",
    "\n",
    "factory = EpisodeFactory(\"../data/jre\")\n",
    "episodes = factory.create_episodes(skip_comments=True)\n",
    "\n",
    "with open(CACHE, \"wb\") as f:\n",
    "    if CACHE == CACHE_SMALL:\n",
    "        pickle.dump(episodes[:100], f)\n",
    "    else:\n",
    "        pickle.dump(episodes, f)\n",
    "\n",
    "print(f\"Number of loaded episodes: {len(episodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:33:48.992799Z",
     "start_time": "2020-11-30T08:33:48.894182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>number</th>\n",
       "      <th>published</th>\n",
       "      <th>guests</th>\n",
       "      <th>main</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>views</th>\n",
       "      <th>commentCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6540Nct67uw</td>\n",
       "      <td>Joe Rogan Experience #1571 - Emily Harrington</td>\n",
       "      <td>1571.0</td>\n",
       "      <td>2020-11-27T18:00:01Z</td>\n",
       "      <td>Emily Harrington</td>\n",
       "      <td>True</td>\n",
       "      <td>14276</td>\n",
       "      <td>960</td>\n",
       "      <td>999045</td>\n",
       "      <td>3946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bvzs-VbEzds</td>\n",
       "      <td>Joe Rogan Experience #1570 - Willie D &amp; Mike J...</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>2020-11-25T18:00:26Z</td>\n",
       "      <td>Willie D &amp; Mike Judge</td>\n",
       "      <td>True</td>\n",
       "      <td>18062</td>\n",
       "      <td>1351</td>\n",
       "      <td>1230183</td>\n",
       "      <td>6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHXIQhvI8cw</td>\n",
       "      <td>Joe Rogan Experience #1569 - John Mackey</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>2020-11-24T18:00:02Z</td>\n",
       "      <td>John Mackey</td>\n",
       "      <td>True</td>\n",
       "      <td>19961</td>\n",
       "      <td>4814</td>\n",
       "      <td>1492106</td>\n",
       "      <td>13619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2Wk6SL4ofG0</td>\n",
       "      <td>Joe Rogan Experience #1568 - Tom Green</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>2020-11-20T18:00:01Z</td>\n",
       "      <td>Tom Green</td>\n",
       "      <td>True</td>\n",
       "      <td>32754</td>\n",
       "      <td>1798</td>\n",
       "      <td>2254148</td>\n",
       "      <td>14013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C7t_LxpzYTg</td>\n",
       "      <td>Joe Rogan Experience #1567 - Donnell Rawlings ...</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>2020-11-19T18:00:01Z</td>\n",
       "      <td>Donnell Rawlings &amp; Dave Chappelle</td>\n",
       "      <td>True</td>\n",
       "      <td>139783</td>\n",
       "      <td>8702</td>\n",
       "      <td>6923358</td>\n",
       "      <td>42576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  number  \\\n",
       "0  6540Nct67uw      Joe Rogan Experience #1571 - Emily Harrington  1571.0   \n",
       "1  bvzs-VbEzds  Joe Rogan Experience #1570 - Willie D & Mike J...  1570.0   \n",
       "2  CHXIQhvI8cw           Joe Rogan Experience #1569 - John Mackey  1569.0   \n",
       "3  2Wk6SL4ofG0             Joe Rogan Experience #1568 - Tom Green  1568.0   \n",
       "4  C7t_LxpzYTg  Joe Rogan Experience #1567 - Donnell Rawlings ...  1567.0   \n",
       "\n",
       "              published                             guests  main   likes  \\\n",
       "0  2020-11-27T18:00:01Z                   Emily Harrington  True   14276   \n",
       "1  2020-11-25T18:00:26Z              Willie D & Mike Judge  True   18062   \n",
       "2  2020-11-24T18:00:02Z                        John Mackey  True   19961   \n",
       "3  2020-11-20T18:00:01Z                          Tom Green  True   32754   \n",
       "4  2020-11-19T18:00:01Z  Donnell Rawlings & Dave Chappelle  True  139783   \n",
       "\n",
       "  dislikes    views commentCount  \n",
       "0      960   999045         3946  \n",
       "1     1351  1230183         6335  \n",
       "2     4814  1492106        13619  \n",
       "3     1798  2254148        14013  \n",
       "4     8702  6923358        42576  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save CSV version of this to website directory\n",
    "ep_df = pd.DataFrame(\n",
    "    [\n",
    "        (e.video_id, e.title, e.number, e.published_at, e.guests, e.is_main_episode, e.likes, e.dislikes, e.views, e.comment_count) \n",
    "         for e in episodes\n",
    "    ],\n",
    "    columns=[\"id\", \"title\", \"number\", \"published\", \"guests\", \"main\", \"likes\", \"dislikes\",\"views\",\"commentCount\"]\n",
    ")\n",
    "\n",
    "ep_df.to_csv(WEBSITE + \"episodes.csv\")\n",
    "ep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T19:39:31.302745Z",
     "start_time": "2020-11-27T19:39:24.438275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total main episodes 1470\n"
     ]
    }
   ],
   "source": [
    "# Kinda dumb but too lazy to fix this, go generate pickle file in 1.gen_episodes first\n",
    "CACHE = \"./jre-episodes.pickle\"\n",
    "\n",
    "with open(CACHE, \"rb\") as f:\n",
    "    episodes = pickle.load(f)\n",
    "\n",
    "main_eps = [e for e in episodes if e.is_main_episode]\n",
    "print(\"Total main episodes\", len(main_eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:30:34.646070Z",
     "start_time": "2020-11-27T20:22:31.764763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing main videos 11\n",
      "[youtube] wC5TVZ3p_H4: Downloading webpage\n",
      "[download] Destination: Joe Rogan Experience #1548 - Roy Jones Jr.-wC5TVZ3p_H4.mp4\n",
      "[download] 100% of 306.32MiB in 00:2467MiB/s ETA 00:005\n",
      "0\n",
      "[youtube] ckjwkCbGIu8: Downloading webpage\n",
      "[download] Destination: Joe Rogan Experience #1547 - Colin Quinn-ckjwkCbGIu8.mp4\n",
      "[download] 100% of 367.64MiB in 00:2737MiB/s ETA 00:002\n",
      "0\n",
      "[youtube] A9PfeA9qFp8: Downloading webpage\n",
      "[download] Destination: Joe Rogan Experience #1546 - Evan Hafer & Mat Best-A9PfeA9qFp8.mp4\n",
      "[download] 100% of 431.54MiB in 00:2803MiB/s ETA 00:002\n",
      "0\n",
      "[youtube] j-bSjzIPRro: Downloading webpage\n",
      "[download] Destination: Joe Rogan Experience #1545 - W. Keith Campbell-j-bSjzIPRro.mp4\n",
      "[download] 100% of 430.29MiB in 00:2899MiB/s ETA 00:001\n",
      "0\n",
      "[youtube] ikJq6wcgrXI: Downloading webpage\n",
      "[download] Destination: Joe Rogan Experience #1544 - Tim Dillon-ikJq6wcgrXI.mp4\n",
      "[download] 100% of 400.05MiB in 00:2442MiB/s ETA 00:001\n",
      "0\n",
      "[youtube] gzAQ7SklDxo: Downloading webpage\n",
      "[download] Destination: Joe Rogan Experience #1543 - Brian Muraresku & Graham Hancock-gzAQ7SklDxo.mp4\n",
      "[download] 100% of 447.81MiB in 00:2762MiB/s ETA 00:007\n",
      "0\n",
      "[youtube] EURQLMDNdw8: Downloading webpage\n",
      "[download] Destination: Joe Rogan Experience #1542 - Cameron Hanes-EURQLMDNdw8.mp4\n",
      "[download] 100% of 432.65MiB in 00:3319MiB/s ETA 00:008\n",
      "0\n",
      "[youtube] DYpotjw_KTw: Downloading webpage\n",
      "[download] Destination: Joe Rogan Experience #1541 - Bridget Phetasy-DYpotjw_KTw.mp4\n",
      "[download] 100% of 515.91MiB in 00:3288MiB/s ETA 00:007\n",
      "0\n",
      "[youtube] Kv3dsPkTvhY: Downloading webpage\n",
      "[download] Destination: Joe Rogan Experience #1540 - Frank von Hippel-Kv3dsPkTvhY.mp4\n",
      "[download] 100% of 410.34MiB in 00:2671MiB/s ETA 00:005\n",
      "0\n",
      "[youtube] LNw8cGy7R_s: Downloading webpage\n",
      "[youtube] LNw8cGy7R_s: Downloading embed webpage\n",
      "[youtube] LNw8cGy7R_s: Refetching age-gated info webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: This video is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not download Joe Rogan Experience #674 - Brian Redban\n",
      "[youtube] 0swiKKUHIiU: Downloading webpage\n",
      "[youtube] 0swiKKUHIiU: Downloading embed webpage\n",
      "[youtube] 0swiKKUHIiU: Refetching age-gated info webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: This video contains content from NFL, who has blocked it on copyright grounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not download Joe Rogan Experience #572 - Dom Irrera\n",
      "Downloaded 9 videos\n"
     ]
    }
   ],
   "source": [
    "video_files = list(glob(VIDEOS_LOCATION + \"*.mp4\"))\n",
    "video_files_ids = [v[-15:-4] for v in video_files]\n",
    "downloaded_main = [e for e in main_eps if e.video_id in video_files_ids]\n",
    "\n",
    "# sort to give priority to newer episodes first\n",
    "missing_videos = sorted(\n",
    "    list(set(main_eps) - set(downloaded_main)), \n",
    "    key=lambda ep: ep.number, \n",
    "    reverse=True,\n",
    ")\n",
    "\n",
    "print(\"Total missing main videos\", len(missing_videos))\n",
    "\n",
    "ydl = youtube_dl.YoutubeDL(\n",
    "    {\n",
    "        # MP4 at 360p\n",
    "        \"format\": \"18\",\n",
    "        # \"cookiefile\": \"./youtube-dl-cookies.txt\"\n",
    "    }\n",
    ")\n",
    "\n",
    "downloaded = 0\n",
    "with ydl:\n",
    "    for ep in missing_videos:\n",
    "        video = f\"http://www.youtube.com/watch?v={ep.video_id}\"\n",
    "\n",
    "        try:\n",
    "            result = ydl.download([video])\n",
    "            print(result)\n",
    "            downloaded += 1\n",
    "            \n",
    "            # Couldn't get option \"outtml\" to work, manually move instead\n",
    "            try:\n",
    "                file = f\"{ep.title}-{ep.video_id}.mp4\"\n",
    "                shutil.move(f\"./{file}\", VIDEOS_LOCATION + file)\n",
    "            except Exception as e:\n",
    "                print(\"Could not move\", ep, e)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"could not download\", ep.title)\n",
    "        \n",
    "        time.sleep(15)\n",
    "\n",
    "print(\"Downloaded\", downloaded, \"videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused but may be helpful to someone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(videoId, max=1500):\n",
    "    page_token = None\n",
    "    items = []\n",
    "    # print(videoId)\n",
    "\n",
    "    while True and len(items) < max:\n",
    "        # print(f\"\\t{len(items)}/{max}\")\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"id,snippet\",\n",
    "            videoId=videoId,\n",
    "            pageToken=page_token,\n",
    "            maxResults=500,\n",
    "            order=\"relevance\",\n",
    "        )\n",
    "        response = request.execute()\n",
    "        items.extend(response[\"items\"])\n",
    "\n",
    "        if \"nextPageToken\" in response:\n",
    "            page_token = response[\"nextPageToken\"]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return items\n",
    "\n",
    "def get_comments():\n",
    "#     Get comments and statistics for each video\n",
    "    with open(UPLOADS, \"r\") as f:\n",
    "        uploads = json.loads(f.read())\n",
    "\n",
    "        # likeCount, textDisplay, textOriginal, publishedAt\n",
    "        # authorDisplayName, authorChannelId\n",
    "        i = 0\n",
    "        comment_threads = {}\n",
    "        with open(COMMENTS, \"r\") as f:\n",
    "            comment_threads = json.load(f)\n",
    "\n",
    "        for upload in tqdm.tqdm(uploads):\n",
    "            videoId = upload[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
    "\n",
    "            if videoId not in comment_threads:\n",
    "                comments = get_comments(videoId)\n",
    "                comment_threads[videoId] = comments\n",
    "                print(videoId, len(comments))\n",
    "            else:\n",
    "                print(\"Already saved thread for\", videoId)\n",
    "\n",
    "            i += 1\n",
    "            # save progress\n",
    "            if i % 25 == 0:\n",
    "                with open(COMMENTS, \"w\") as f:\n",
    "                    f.write(json.dumps(comment_threads))\n",
    "\n",
    "        with open(COMMENTS, \"w\") as f:\n",
    "            f.write(json.dumps(comment_threads))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use video data instead\n",
    "def download_audio():\n",
    "    audio_file = lambda id: f\"data/jre/audio/{id}\"\n",
    "    with open(UPLOADS, \"r\") as f:\n",
    "        uploads = json.loads(f.read())\n",
    "\n",
    "        for upload in tqdm(uploads):\n",
    "            id = upload[\"contentDetails\"][\"videoId\"]\n",
    "            yt = None\n",
    "            if os.path.exists(audio_file(id)):\n",
    "                print(\"File exists\", id, \"skipping...\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                yt = YouTube(f\"https://www.youtube.com/watch?v={id}\")\n",
    "            except Exception as e:\n",
    "                print(\"Could not load api\", id, str(e))\n",
    "                continue\n",
    "\n",
    "            audio_streams = yt.streams.filter(only_audio=True)\n",
    "\n",
    "            if len(audio_streams) == 0:\n",
    "                print(\"No audio streams available for\", id)\n",
    "                continue\n",
    "\n",
    "            mp4_streams = [s for s in audio_streams if s.mime_type == \"audio/mp4\"]\n",
    "            stream = audio_streams[0] if len(mp4_streams) == 0 else mp4_streams[0]\n",
    "\n",
    "            print(f\"Downloading [{id}] {stream.mime_type} {stream.abr}\")\n",
    "            stream.download(audio_file(id))\n",
    "            print(\"\\t... Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused utils\n",
    "def get_timestamps(c):\n",
    "    timestamp = r\"(\\d?\\d?:)?\\d?\\d?:\\d{2}\"\n",
    "\n",
    "    if \"topLevelComment\" in c[\"snippet\"]:\n",
    "        snippet = c[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "\n",
    "        if re.search(timestamp, snippet[\"textOriginal\"]) is None:\n",
    "            return None\n",
    "        return snippet[\"likeCount\"], snippet[\"textOriginal\"]\n",
    "    elif re.search(timestamp, c[\"snippet\"][\"textOriginal\"]) is not None:\n",
    "        return c[\"snippet\"][\"likeCount\"], c[\"snippet\"][\"textOriginal\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
