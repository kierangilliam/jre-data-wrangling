{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection \n",
    "1. TFIDF For all episodes\n",
    "2. Cosine similarity\n",
    "3. Most spoken words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:39.232227Z",
     "start_time": "2020-11-26T01:44:39.205726Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:39.869305Z",
     "start_time": "2020-11-26T01:44:39.235931Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:39.896885Z",
     "start_time": "2020-11-26T01:44:39.873694Z"
    }
   },
   "outputs": [],
   "source": [
    "WEBSITE = \"../data/jre/website/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.972662Z",
     "start_time": "2020-11-26T01:44:39.901546Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b02da159967a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCACHE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mepisodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of loaded episodes: {len(episodes)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CACHE = \"./jre-episodes.pickle\"\n",
    "\n",
    "with open(CACHE, \"rb\") as f:\n",
    "    episodes = pickle.load(f)\n",
    "\n",
    "print(f\"Number of loaded episodes: {len(episodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.976976Z",
     "start_time": "2020-11-26T01:44:39.219Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lib.TFIDF import TFIDF\n",
    "from lib.utils import clean_text\n",
    "\n",
    "cleaned_corpus = [(e, clean_text(e.text)) for e in tqdm(episodes) if e.captions is not None]\n",
    "# s2w is the stem 2 word dictionary (saved in a later cell)\n",
    "corpus = [(ep, cleaned) for ep, (cleaned, s2w) in cleaned_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.979187Z",
     "start_time": "2020-11-26T01:44:39.222Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TFIDF()\n",
    "tfidf.generate(corpus)\n",
    "\n",
    "with open(\"tfidf-\" + CACHE[2:], \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.981658Z",
     "start_time": "2020-11-26T01:44:39.225Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"tfidf-\" + CACHE[2:], \"rb\") as f:\n",
    "    tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.983750Z",
     "start_time": "2020-11-26T01:44:39.237Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf.print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.986216Z",
     "start_time": "2020-11-26T01:44:39.240Z"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    dist = lambda tfidf: np.sqrt(np.sum(tfidf * tfidf))\n",
    "    dot_prod = np.dot(a, b)\n",
    "    distances = dist(a) * dist(b)\n",
    "    return dot_prod / distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.988064Z",
     "start_time": "2020-11-26T01:44:39.244Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probably the dumbest way to do this\n",
    "tfidf_titles = [e.title for e in tfidf.scores.keys()]\n",
    "index_of_ep = lambda ep: tfidf_titles.index(ep.title)\n",
    "\n",
    "# (ep1, ep2), score\n",
    "cos_sim_matrix = np.zeros((len(episodes), len(episodes)), tuple)\n",
    "\n",
    "for a, b in tqdm([(a, b) for a in tfidf.scores for b in tfidf.scores]):\n",
    "    ai = index_of_ep(a)\n",
    "    bi = index_of_ep(b)\n",
    "    # Only fill half of the matrix\n",
    "    if bi > ai:\n",
    "        continue\n",
    "    cos_sim_matrix[ai][bi] = ((a, b), cosine_similarity(tfidf.scores[a], tfidf.scores[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.989649Z",
     "start_time": "2020-11-26T01:44:39.247Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cos_sim_matrix[:3]), len(cos_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.991536Z",
     "start_time": "2020-11-26T01:44:39.249Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_sim_list = []\n",
    "\n",
    "# Format as (index, index), similarity\n",
    "for row in cos_sim_matrix:\n",
    "    for item in row:\n",
    "        if item == 0: continue\n",
    "        (a, b), score = item\n",
    "        if a == b: continue\n",
    "        cos_sim_list.append((a, b, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.993507Z",
     "start_time": "2020-11-26T01:44:39.252Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Most similar podcast episodes\")\n",
    "print(\"=============================\\n\")\n",
    "cos_sim_list = sorted(cos_sim_list, key=lambda x: x[2], reverse=True)\n",
    "for a, b, score in cos_sim_list[:50]:\n",
    "    if a.is_main_episode and b.is_main_episode:\n",
    "        print(a)\n",
    "        print(b)\n",
    "        print(f\"\\t{round(score, 4) * 100}%\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.995621Z",
     "start_time": "2020-11-26T01:44:39.254Z"
    }
   },
   "outputs": [],
   "source": [
    "cos_sim_table = pd.DataFrame(\n",
    "    [(a.video_id, b.video_id, s) for a,b,s in cos_sim_list], \n",
    "    columns=[\"id1\", \"id2\", \"similarity\"],\n",
    ")\n",
    "cos_sim_table.to_csv(WEBSITE + \"episode_similarity.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To protobufs\n",
    "63mb -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.997801Z",
     "start_time": "2020-11-26T01:44:39.256Z"
    }
   },
   "outputs": [],
   "source": [
    "# protoc --python_out=./ ./episode-sim.proto\n",
    "# protoc --js_out=../../jre-vis/src/lib/proto ./episode-sim.proto\n",
    "import episode_sim_pb2 as ep_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:48.999929Z",
     "start_time": "2020-11-26T01:44:39.260Z"
    }
   },
   "outputs": [],
   "source": [
    "cos_sim_table = pd.read_csv(WEBSITE + \"episode_similarity.csv\")\n",
    "\n",
    "ids = cos_sim_table[\"id1\"].append(cos_sim_table[\"id2\"]).unique()\n",
    "IDs = ep_proto.IDs()\n",
    "for i, id in enumerate(ids):\n",
    "    row = IDs.rows.add()\n",
    "    row.idNum = i\n",
    "    row.id = id\n",
    "    \n",
    "epSims = ep_proto.EpisodeSims()\n",
    "for index, row in tqdm(cos_sim_table.iterrows()):\n",
    "    e = epSims.rows.add()\n",
    "    e.similarity = row[\"similarity\"]\n",
    "    e.idNum1 = [i for i, id in enumerate(ids) if id == row[\"id1\"]][0]\n",
    "    e.idNum2 = [i for i, id in enumerate(ids) if id == row[\"id2\"]][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:49.002211Z",
     "start_time": "2020-11-26T01:44:39.263Z"
    }
   },
   "outputs": [],
   "source": [
    "PROTO_OUT = \"../../jre-vis/public/\"\n",
    "\n",
    "with open(PROTO_OUT + \"ep_sim\", \"wb\") as f:\n",
    "    f.write(epSims.SerializeToString())\n",
    "    \n",
    "with open(PROTO_OUT + \"ep_sim_id_lookup\", \"wb\") as f:\n",
    "    f.write(IDs.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store top word occurrences of each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:49.005201Z",
     "start_time": "2020-11-26T01:44:39.267Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num(e):\n",
    "    # TODO\n",
    "    # unsure why, but the tfidf ep #1564 and #1563 in the cfd\n",
    "    # are strings and not actual episodes\n",
    "    try:\n",
    "        x = e[0].number if e[0].number is not None else -1\n",
    "        return x\n",
    "    except Exception as x:\n",
    "        return -1\n",
    "    \n",
    "cfd_items = sorted(list(tfidf.cfd.items()), key=get_num, reverse=True)\n",
    "cfd_table = pd.DataFrame(\n",
    "    [(k.video_id, dict(v.most_common(400))) for k, v in cfd_items],\n",
    "    columns=[\"id\", \"top_words\"],\n",
    ")\n",
    "\n",
    "cfd_table.to_csv(WEBSITE + \"word_occurrences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Stem Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:44:49.007812Z",
     "start_time": "2020-11-26T01:44:39.281Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_stem = {}\n",
    "for title, (cleaned, s2w) in cleaned_corpus:\n",
    "    reverse_stem.update(s2w)\n",
    "    \n",
    "rm_stem = lambda stem, w: w if len(stem) == len(w) else w[len(stem):]\n",
    "reverse_stem = {stem: [rm_stem(stem, w) for w in words] for stem, words in reverse_stem.items()}\n",
    "\n",
    "# Remove items with 1 element that is the exact same as the stem\n",
    "reverse_stem = {stem: words for stem, words in reverse_stem.items() if len(words) != 1 or words[0] != stem}\n",
    "\n",
    "# Remove words that are the exact same as the stem\n",
    "reverse_stem = {stem: [w for w in words if w != stem] for stem, words in reverse_stem.items()}\n",
    "    \n",
    "with open(WEBSITE + \"reverse_stem.json\", \"w\") as f:\n",
    "    f.write(json.dumps(reverse_stem))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
