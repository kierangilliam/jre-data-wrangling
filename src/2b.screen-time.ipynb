{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:11:28.372293Z",
     "start_time": "2020-11-27T21:11:27.522682Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Video\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:11:28.376084Z",
     "start_time": "2020-11-27T21:11:28.374008Z"
    }
   },
   "outputs": [],
   "source": [
    "WEBSITE = \"../../jre-vis/public/\"\n",
    "# TODO How to estimate bandwidth for 2d data?\n",
    "BANDWIDTH = .1\n",
    "AVGS_LOCATION = \"averages_scale.25.0_color\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:11:28.381914Z",
     "start_time": "2020-11-27T21:11:28.377995Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_frame_from(ep, frame_no):\n",
    "    video_name = [v for v in video_files if ep.title in v][0]\n",
    "    cap = cv2.VideoCapture(video_name)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)    \n",
    "    plt.title(as_timestamp(frame_no, fps))\n",
    "    _, frame = cap.read()\n",
    "    plt.imshow(frame)\n",
    "    cap.release()\n",
    "    \n",
    "def as_timestamp(frame_no, fps):\n",
    "    sec = frame_no / fps\n",
    "    return f\"{floor(sec / 60 / 60)}:{floor(sec / 60) % 60}:{round(sec % 60, 1)}\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:11:29.209481Z",
     "start_time": "2020-11-27T21:11:28.384883Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.neighbors.kde module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth, KMeans, DBSCAN\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "def kde_cluster(Xdf, kernel=\"gaussian\", bandwidth=10, plot=False):\n",
    "    \"\"\"\n",
    "    Uses KDE to create clusters out of word vecs\n",
    "    \"\"\"\n",
    "    X = np.array(Xdf['x'])\n",
    "    X = X.reshape(-1, 1)\n",
    "\n",
    "    # TODO There is probably bias at the boundaries, should mirror X\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(X)\n",
    "    s = np.linspace(0, np.max(X)*1.5)\n",
    "    e = kde.score_samples(s.reshape(-1, 1))\n",
    "\n",
    "    # Reshape back to a 1 by N array\n",
    "    X = X.reshape(1, -1)\n",
    "\n",
    "    minima = argrelextrema(e, np.less)[0]\n",
    "    # Use the linspace to convert back into word indexes\n",
    "    minima = [s[m] for m in minima]\n",
    "    # (0, minima 1), (minima 1, minima 2), ... (minima n-1, minima n), (minima n, end)\n",
    "    minima_pairs = list(zip(np.insert(minima, 0, 0), np.append(minima, s[-1])))\n",
    "\n",
    "    clusters = [\n",
    "      np.unique(X[np.logical_and(X >= m1, X < m2)]) for m1, m2 in minima_pairs\n",
    "    ]\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(s, e)\n",
    "        plt.show()\n",
    "        print(f\"Number of clusters: {len(clusters)}\")\n",
    "        for c in clusters:\n",
    "            print(\"\\t\", len(c), np.unique([int(x) for x in c]))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "# Store frame numbers in the clusters instead of the average of the last frame\n",
    "def frame_idxs_clusters(avg_clusters, df):\n",
    "    df['cluster'] = np.full_like((len(avg_clusters)), -1)\n",
    "\n",
    "    for cluster_number, c in enumerate(avg_clusters):\n",
    "        cluster_cond = (df['x'] >= np.min(c)) & (df['x'] <= np.max(c))\n",
    "        df.loc[cluster_cond, 'cluster'] = cluster_number\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:11:35.843726Z",
     "start_time": "2020-11-27T21:11:29.211140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded episodes: 2462\n"
     ]
    }
   ],
   "source": [
    "CACHE = \"./jre-episodes.pickle\"\n",
    "\n",
    "with open(CACHE, \"rb\") as f:\n",
    "    episodes = pickle.load(f)\n",
    "\n",
    "print(f\"Number of loaded episodes: {len(episodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Averages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:11:44.467899Z",
     "start_time": "2020-11-27T21:11:35.845020Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "AVERAGES = f\"../data/jre/{AVGS_LOCATION}\"\n",
    "\n",
    "for file in os.listdir(AVERAGES):\n",
    "    matches = re.search(r\"-([A-Za-z0-9-_]*).npy\", file)\n",
    "    video_id = matches[1][-11:]\n",
    "    \n",
    "    try:\n",
    "        episode = [e for e in episodes if e.video_id == video_id][0]\n",
    "        episode.video_averages = np.load(\n",
    "            f\"{AVERAGES}/{file}\", allow_pickle=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Could not load video average data for \", video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:41:20.391212Z",
     "start_time": "2020-11-26T01:41:20.359299Z"
    }
   },
   "source": [
    "Main episodes vs main episodes with video averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:11:44.516783Z",
     "start_time": "2020-11-27T21:11:44.474136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470, 1465)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = [ep for ep in episodes if ep.video_averages is not None and ep.is_main_episode]\n",
    "len([ep for ep in episodes if ep.is_main_episode]), len(eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Clusters For Each Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:11:44.538521Z",
     "start_time": "2020-11-27T21:11:44.524423Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_frame_count(ep):\n",
    "    try:\n",
    "        video_name = [v for v in video_files if ep.title in v][0]\n",
    "    except IndexError as e:\n",
    "        print(\"Could not find video\", ep)\n",
    "        raise e\n",
    "\n",
    "    cap = cv2.VideoCapture(video_name)\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    return frames, fps\n",
    "\n",
    "def create_episode_clusters():\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    episode_clusters = []\n",
    "    for ep in tqdm(eps):\n",
    "        averages, total_frames = ep.video_averages\n",
    "        df = pd.DataFrame({\n",
    "          'x': averages,\n",
    "          'n': range(len(averages)),\n",
    "        })\n",
    "\n",
    "        avg_clusters = kde_cluster(df, bandwidth=BANDWIDTH, plot=False)\n",
    "        df = frame_idxs_clusters(avg_clusters, df)\n",
    "\n",
    "        clusters = {}\n",
    "        curr_cluster = df['cluster'][0]        \n",
    "        playhead_start = 0\n",
    "        skip_amount = total_frames / len(averages)\n",
    "        playhead = lambda cluster_idx: (cluster_idx * skip_amount) / total_frames\n",
    "        \n",
    "        for i, cluster_num in enumerate(df['cluster']):\n",
    "            if cluster_num != curr_cluster:\n",
    "                clusters[curr_cluster] = clusters.get(curr_cluster, []) + [(playhead_start, playhead(i - 1))]\n",
    "                playhead_start = playhead(i)\n",
    "                curr_cluster = cluster_num\n",
    "                \n",
    "        episode_clusters.append((ep, clusters))\n",
    "        \n",
    "    return episode_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:26:07.891670Z",
     "start_time": "2020-11-27T21:11:44.547320Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1465/1465 [14:08<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE = f\"./episode-clusters___{AVGS_LOCATION}.pkl\"\n",
    "# LOAD = True\n",
    "LOAD = False\n",
    "\n",
    "episode_clusters = []\n",
    "\n",
    "if LOAD:\n",
    "    with open(CACHE, \"rb\") as f:\n",
    "        episode_clusters = pickle.load(f)\n",
    "else:\n",
    "    episode_clusters = create_episode_clusters()\n",
    "    with open(CACHE, \"wb\") as f:\n",
    "        pickle.dump(episode_clusters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T22:04:13.399525Z",
     "start_time": "2020-11-27T22:04:13.392040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ep clusters\n",
      "19\n",
      "Missing ep clusters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19,\n",
       " ['Joe Rogan Experience #868 - John Dudley (Audio Only)',\n",
       "  'Joe Rogan Experience #834 - Dan Doty',\n",
       "  'Joe Rogan Experience #827 - Twitter Q&A with Joe',\n",
       "  'Joe Rogan Experience #722 - Tony Hinchcliffe (Audio Only)',\n",
       "  'Joe Rogan Experience #211 - Ari Shaffir (Part 2)',\n",
       "  'Joe Rogan Experience #185 - Tom Segura',\n",
       "  'Joe Rogan Experience #143 - Mayhem Miller',\n",
       "  'Joe Rogan Experience #140 - Brendon Walsh (Part 2)',\n",
       "  'Joe Rogan Experience #132 - Bert Kreischer',\n",
       "  'Joe Rogan Experience #119 - Jan Irvin',\n",
       "  'Joe Rogan Experience #47 - Michael Schiavello',\n",
       "  'Joe Rogan Experience #39 - Joey Diaz, Eddie Bravo (Part 1)',\n",
       "  'Joe Rogan Experience #37 - Ricky Schroder',\n",
       "  'Joe Rogan Experience #33 -- Dane Cook',\n",
       "  'Joe Rogan Experience #31 -- Mayhem Miller',\n",
       "  'Joe Rogan Experience #29 - Brian Redban',\n",
       "  'Joe Rogan Experience #26 - Bill Burr',\n",
       "  'Joe Rogan Experience #15 - Brian Redban',\n",
       "  'Joe Rogan Experience #14 - Brian Redban'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total ep clusters\")\n",
    "print(len(missing_ep_clusters))\n",
    "\n",
    "missing_ep_clusters = [e for e,c in episode_clusters if len(c.items()) == 0]\n",
    "\n",
    "print(\"Missing ep clusters\")\n",
    "len(missing_ep_clusters), [e.title for e in missing_ep_clusters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate pie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:26:08.405796Z",
     "start_time": "2020-11-27T21:26:07.902996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1465"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pie_rows = []\n",
    "for ep, cluster_timestamps in episode_clusters:\n",
    "    data = {}\n",
    "    for i, t in cluster_timestamps.items():\n",
    "        data[i] = 0\n",
    "        for start, end in t:\n",
    "            data[i] += end - start\n",
    "\n",
    "    pie_rows.append([ep.video_id, dict(data)])\n",
    "            \n",
    "pie_data = pd.DataFrame(pie_rows, columns=[\"id\", \"data\"])\n",
    "pie_data.to_csv(WEBSITE + \"screen_time.csv\")\n",
    "len(pie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:26:10.749541Z",
     "start_time": "2020-11-27T21:11:27.547Z"
    }
   },
   "outputs": [],
   "source": [
    "type(episode_clusters[0][1].keys()), episode_clusters[0][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:26:10.751323Z",
     "start_time": "2020-11-27T21:11:27.549Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Protobufs are 16mb.. json is 60ish\n",
    "import json\n",
    "\n",
    "def key_to_json(data):\n",
    "    if data is None or isinstance(data, (bool, int, str)):\n",
    "        return data\n",
    "    if isinstance(data, (tuple, frozenset)):\n",
    "        return str(data)\n",
    "    if isinstance(data, np.int64):\n",
    "        return int(data)\n",
    "    raise Exception(\"Type error\", (data, type(data)))\n",
    "\n",
    "def to_json(data):\n",
    "    if data is None or isinstance(data, (bool, int, tuple, range, str, list)):\n",
    "        return data\n",
    "    if isinstance(data, (set, frozenset)):\n",
    "        return sorted(data)\n",
    "    if isinstance(data, dict):\n",
    "        return {key_to_json(key): to_json(data[key]) for key in data}\n",
    "    raise TypeError\n",
    "\n",
    "with open(PROTO_OUT + \"screen_time_timelines.json\", \"w\") as f:\n",
    "    if False:\n",
    "        json_ep_clusters = json.dumps(to_json({e.video_id:cl for e, cl in episode_clusters}))\n",
    "        f.write(json_ep_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get pictures for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T02:09:35.175624Z",
     "start_time": "2020-11-28T01:54:38.734747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1465/1465 [14:55<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "import imutils\n",
    "\n",
    "video_files = list(glob(\"/Volumes/JRE/jre-bucket/jre/videos/*.mp4\"))\n",
    "\n",
    "BLACK_AND_WHITE = True\n",
    "RESCALE_AMOUNT = .5\n",
    "\n",
    "def rescale_frame(frame, amount=.75):\n",
    "    width = int(frame.shape[1] * amount)\n",
    "    height = int(frame.shape[0] * amount)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "\n",
    "video_cluster_images = {}\n",
    "total = 0\n",
    "for ep, cluster_timestamps in tqdm(episode_clusters):\n",
    "    video_cluster_images[ep] = {}\n",
    "    \n",
    "    try:\n",
    "        video_name = [v for v in video_files if ep.video_id == v[-15:-4]][0]\n",
    "    except IndexError as e:\n",
    "        print(\"Could not find video\", ep)\n",
    "        continue\n",
    "    \n",
    "    # Get a frame for the middle of each cluster timestamp\n",
    "    for i, t in cluster_timestamps.items():\n",
    "        cap = cv2.VideoCapture(video_name)\n",
    "        frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "       \n",
    "        # Get the segment in the cluster with the longest time on that shot\n",
    "        start, end = t[np.argmax([e - s for s, e in t])]\n",
    "        middle = (end - start) / 2 + start\n",
    "        # Don't get pictures for items with less than .1% of the total time\n",
    "        if end - start < .001:            \n",
    "            continue\n",
    "        total += 1\n",
    "        \n",
    "        # Read frame        \n",
    "        frame_no = int(frames * middle)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n",
    "        \n",
    "        averages, _ = ep.video_averages\n",
    "        \n",
    "        ret, frame = cap.read()                \n",
    "\n",
    "        frame = rescale_frame(frame, amount=RESCALE_AMOUNT)\n",
    "        if BLACK_AND_WHITE: frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        video_cluster_images[ep][i] = {'frame':frame, 'frame_no':frame_no, 'frames':frames, 'fps':fps}        \n",
    "        \n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T02:18:54.481213Z",
     "start_time": "2020-11-28T02:18:54.414446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1465, 19)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_video_cluster_images = [k for k,v in video_cluster_images.items() if len(v.items()) == 0]\n",
    "len(video_cluster_images), len(missing_video_cluster_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:58:35.925021Z",
     "start_time": "2020-11-26T02:58:35.920984Z"
    }
   },
   "source": [
    "## Save Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T02:19:05.835016Z",
     "start_time": "2020-11-28T02:18:56.078628Z"
    }
   },
   "outputs": [],
   "source": [
    "for ep, clusters in video_cluster_images.items():\n",
    "    for cluster_n, image in clusters.items():\n",
    "        cv2.imwrite(f\"{WEBSITE}/images/{ep.video_id}.cluster.{cluster_n}.jpg\", image['frame'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create timeline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:26:08.531941Z",
     "start_time": "2020-11-27T21:26:08.407337Z"
    }
   },
   "outputs": [],
   "source": [
    "# protoc --python_out=./ ./screen-time-timeline.proto\n",
    "# pbf screen-time-timeline.proto --browser > ../../jre-vis/src/lib/proto/screen-time.js\n",
    "import screen_time_timeline_pb2 as timeline_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:53:46.445617Z",
     "start_time": "2020-11-28T00:53:42.491101Z"
    }
   },
   "outputs": [],
   "source": [
    "timelines = timeline_proto.Timelines()\n",
    "\n",
    "for ep, cluster_timestamps in episode_clusters:\n",
    "    if len(list(video_cluster_images[ep].values())) == 0:\n",
    "        continue\n",
    "        \n",
    "    timeline = timelines.timelines.add()\n",
    "    timeline.id = ep.video_id\n",
    "    timeline.frames = list(video_cluster_images[ep].values())[0]['frames']    \n",
    "    \n",
    "    for i, t in cluster_timestamps.items():\n",
    "        # If it doesn't have a picture, don't bother\n",
    "        if not i in video_cluster_images[ep]:\n",
    "            continue\n",
    "        \n",
    "        cluster = timeline.clusters.add()\n",
    "        cluster.id = i\n",
    "        for start, end in t:\n",
    "            ts = cluster.timestamps.add()\n",
    "            ts.start = start\n",
    "            ts.end = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:53:48.944316Z",
     "start_time": "2020-11-28T00:53:48.522591Z"
    }
   },
   "outputs": [],
   "source": [
    "PROTO_OUT = \"../../jre-vis/public/\"\n",
    "\n",
    "with open(PROTO_OUT + \"screen_time_timelines\", \"wb\") as f:\n",
    "    f.write(timelines.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Images\n",
    "Image is shown above scatterplot\n",
    "Its corressponding cluster is highlighted in green\n",
    "The orange dot indicates the frame it was taken from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T01:11:55.572369Z",
     "start_time": "2020-11-28T01:11:45.838010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4ac283865c4fafbc1dbba2848a32a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28c3e52336c4af9aae7f22f1f705f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, max=1464)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ee608300ef4f97a23ca7826d8b8193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Cluster:', options=(0, 1), value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider, Dropdown\n",
    "%matplotlib inline\n",
    "from ipywidgets.widgets.interaction import show_inline_matplotlib_plots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def show_video_segments():\n",
    "    def get_title(ep, cluster, timestamp):\n",
    "        try:\n",
    "            percentage = pie_data.loc[pie_data['id'] == ep.video_id]['data'].iloc[0][cluster]\n",
    "        except Exception as e:\n",
    "            percentage = 0\n",
    "            print(\"Could not get percentage for\", ep.number)\n",
    "        return f\"{ep.title} -- {cluster} ({round(percentage * 100)}%, {timestamp})\"\n",
    "    \n",
    "    cluster = choose_cluster.value        \n",
    "    ep, cluster_images = list(video_cluster_images.items())[ep_slider.value]\n",
    "    img = cluster_images[cluster]\n",
    "    \n",
    "    averages = ep.video_averages[0]\n",
    "    df = pd.DataFrame({ 'x': averages, 'n': range(len(averages))})\n",
    "    avg_clusters = kde_cluster(df, bandwidth=BANDWIDTH, plot=False)\n",
    "    df = frame_idxs_clusters(avg_clusters, df)\n",
    "    df['color'] = np.where(df['cluster'] == cluster, 'green', 'black')\n",
    "\n",
    "    with out:\n",
    "        clear_output()                \n",
    "        fig, (img_ax, clus_ax) = plt.subplots(2)\n",
    "        fig.suptitle(get_title(ep, cluster, as_timestamp(img['frame_no'], img['fps'])))        \n",
    "        \n",
    "        # Show frame image\n",
    "        if BLACK_AND_WHITE: img_ax.imshow(img['frame'], cmap='gray')\n",
    "        else: img_ax.imshow(img['frame'])\n",
    "\n",
    "        # Show scatter plot of clusters\n",
    "        # Highlight the frame that was used as orange\n",
    "        clus_ax.scatter(df['x'], y=df['n'], c=df['color'])        \n",
    "        cluster_frame = int(img['frame_no'] / img['frames'] * len(df['color']))\n",
    "        clus_ax.scatter(df.loc[cluster_frame, 'x'], y=df.loc[cluster_frame, 'n'], c='orange')\n",
    "\n",
    "        show_inline_matplotlib_plots()\n",
    "        \n",
    "    \n",
    "def on_cluster_change(change):\n",
    "    show_video_segments()\n",
    "    \n",
    "def on_ep_change(change):\n",
    "    new_x = change['new']\n",
    "    ep, clusters = list(video_cluster_images.items())[new_x]\n",
    "    choose_cluster.options = clusters.keys()\n",
    "    choose_cluster.value = list(clusters.keys())[0]    \n",
    "    show_video_segments()\n",
    "\n",
    "initial_ep = 0\n",
    "\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "    \n",
    "choose_cluster = Dropdown(description='Cluster:')\n",
    "choose_cluster.observe(on_cluster_change, names='value')\n",
    "\n",
    "ep_slider = IntSlider(min=0, max=len(video_cluster_images) - 1)\n",
    "ep_slider.observe(on_ep_change, names='value')\n",
    "ep_slider.value = initial_ep\n",
    "on_ep_change({'new': initial_ep})\n",
    "\n",
    "display(ep_slider, choose_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful for checking out output of kde \n",
    "...With different values for the bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T05:34:50.214349Z",
     "start_time": "2020-11-28T05:34:45.559102Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738b069bc1d8459abc25f5f67ed7c387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='x', max=1464), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_frame_averages(x)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from ipywidgets import interact, IntSlider\n",
    "py.offline.init_notebook_mode(connected = True)\n",
    "\n",
    "bandwidth = BANDWIDTH\n",
    "bandwidth = .01\n",
    "frame_no = 194000\n",
    "\n",
    "def show_frame_from(ep, frame_no):\n",
    "    video_name = [v for v in video_files if ep.video_id == v[-15:-4]][0]\n",
    "    cap = cv2.VideoCapture(video_name)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)    \n",
    "    plt.title(as_timestamp(frame_no, fps))\n",
    "    _, frame = cap.read()\n",
    "    plt.imshow(frame)\n",
    "    cap.release()\n",
    "\n",
    "def show_frame_averages(x):\n",
    "    df = pd.DataFrame({\n",
    "      'x': eps[x].video_averages[0],\n",
    "      'n': range(len(eps[x].video_averages[0])),\n",
    "    })\n",
    "    \n",
    "    avg_clusters = kde_cluster(df, plot=False, bandwidth=bandwidth)\n",
    "\n",
    "    df = frame_idxs_clusters(avg_clusters, df)\n",
    "    # For a discrete color scale\n",
    "    df['cluster'] = df['cluster'].astype(str)\n",
    "    \n",
    "    show_frame_from(eps[x], frame_no)\n",
    "\n",
    "    title = f\"{str(eps[x])} {len(df['x'])}\"\n",
    "    fig = px.scatter(df, x='x', color='cluster', title=title)\n",
    "    fig.show()\n",
    "        \n",
    "\n",
    "interact(show_frame_averages, x=IntSlider(value=9, min=0, max=len(eps) - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Need some way to flag large deviations in std for clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
