{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection \n",
    "1. TFIDF For all episodes\n",
    "2. Cosine similarity\n",
    "3. Most spoken words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T20:08:02.054778Z",
     "start_time": "2020-11-25T20:08:02.041647Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T20:08:04.387281Z",
     "start_time": "2020-11-25T20:08:03.967364Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from lib.Episode import Episode, EpisodeFactory\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T20:08:07.056506Z",
     "start_time": "2020-11-25T20:08:07.042426Z"
    }
   },
   "outputs": [],
   "source": [
    "WEBSITE = \"../data/jre/website/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T20:08:14.612261Z",
     "start_time": "2020-11-25T20:08:08.187900Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded episodes: 2455\n"
     ]
    }
   ],
   "source": [
    "CACHE = \"./jre-episodes.pickle\"\n",
    "\n",
    "with open(CACHE, \"rb\") as f:\n",
    "    episodes = pickle.load(f)\n",
    "\n",
    "print(f\"Number of loaded episodes: {len(episodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T20:13:19.123726Z",
     "start_time": "2020-11-25T20:08:14.614136Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2455/2455 [05:03<00:00,  8.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from lib.TFIDF import TFIDF\n",
    "from lib.utils import clean_text\n",
    "\n",
    "cleaned_corpus = [(e, clean_text(e.text)) for e in tqdm(episodes) if e.captions is not None]\n",
    "# s2w is the stem 2 word dictionary (saved in a later cell)\n",
    "corpus = [(ep, cleaned) for ep, (cleaned, s2w) in cleaned_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDF()\n",
    "tfidf.generate(corpus)\n",
    "\n",
    "with open(\"tfidf-\" + CACHE[2:], \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T18:11:53.110985Z",
     "start_time": "2020-11-17T18:11:42.072983Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"tfidf-\" + CACHE[2:], \"rb\") as f:\n",
    "    tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T18:11:53.818846Z",
     "start_time": "2020-11-17T18:11:53.113304Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5PrLGhJnO7I] Joe Rogan Experience #1562 - Dave Smith\n",
      "biden 0.05818\n",
      "trump 0.04458\n",
      "donald 0.02456\n",
      "war 0.02365\n",
      "eisenhow 0.01875\n",
      "kamala 0.0173\n",
      "iraq 0.01719\n",
      "berni 0.01524\n",
      "sander 0.01477\n",
      "presid 0.01458\n",
      "\n",
      "[C8M1ZRYt-2Q] Joe Rogan Experience #1561 - Kermit Pattison\n",
      "skeleton 0.11077\n",
      "arti 0.07024\n",
      "fossil 0.06021\n",
      "speci 0.05503\n",
      "canin 0.05235\n",
      "luci 0.04657\n",
      "ethiopia 0.04222\n",
      "ancestor 0.03516\n",
      "neanderth 0.03393\n",
      "geolog 0.03041\n",
      "\n",
      "[surnFz_pZE4] Joe Rogan Experience #1559 - Steven Rinella\n",
      "mammoth 0.01885\n",
      "biden 0.01734\n",
      "d-day 0.01474\n",
      "wolv 0.01438\n",
      "hunt 0.01364\n",
      "baculum 0.01355\n",
      "fossil 0.01321\n",
      "overproduc 0.01263\n",
      "bear 0.0122\n",
      "bone 0.01207\n",
      "\n",
      "[KkjxSKrcbOg] JRE End Of The World #2\n",
      "biden 0.08188\n",
      "pennsylvania 0.06654\n",
      "trump 0.06647\n",
      "vote 0.04906\n",
      "poll 0.03987\n",
      "mail-in 0.02748\n",
      "win 0.02549\n",
      "florida 0.02362\n",
      "elect 0.02322\n",
      "ohio 0.02006\n",
      "\n",
      "[OaTKaHKCAFg] Joe Rogan Experience #1558 - Tristan Harris\n",
      "facebook 0.0467\n",
      "attent 0.02281\n",
      "social 0.02155\n",
      "algorithm 0.01919\n",
      "voodoo 0.01893\n",
      "huxley 0.01873\n",
      "orwel 0.0171\n",
      "dilemma 0.01542\n",
      "media 0.01538\n",
      "ukulel 0.01516\n",
      "\n",
      "[4ugp6FBq6E0] Joe Rogan Experience #1557 - Gad Saad\n",
      "intellectu 0.01846\n",
      "victimolog 0.01642\n",
      "regret 0.01605\n",
      "jillian 0.0142\n",
      "publish 0.01409\n",
      "academ 0.01374\n",
      "biden 0.01314\n",
      "lockdown 0.01296\n",
      "narrat 0.01275\n",
      "parasit 0.01235\n",
      "\n",
      "[t0rcLsoIKgA] Joe Rogan Experience #1556 - Glenn Greenwald\n",
      "snowden 0.03726\n",
      "biden 0.03162\n",
      "journalist 0.02728\n",
      "tran 0.01994\n",
      "martina 0.01875\n",
      "govern 0.01668\n",
      "brazil 0.01584\n",
      "trump 0.01477\n",
      "censorship 0.01455\n",
      "aclu 0.01327\n",
      "\n",
      "[jdVso9FSkmE] Joe Rogan Experience #1555 - Alex Jones & Tim Dillon\n",
      "carbon 0.03558\n",
      "dioxid 0.03272\n",
      "whitmer 0.02874\n",
      "vaccin 0.02714\n",
      "trump 0.0269\n",
      "bohemian 0.02458\n",
      "grove 0.02299\n",
      "polio 0.02289\n",
      "u.n 0.02154\n",
      "elect 0.01761\n",
      "\n",
      "[qxOeWuAHOiw] Joe Rogan Experience #1554 - Kanye West\n",
      "donda 0.02097\n",
      "leader 0.01834\n",
      "gap 0.01631\n",
      "industri 0.01549\n",
      "design 0.01522\n",
      "disney 0.01495\n",
      "three-fifth 0.01407\n",
      "visionari 0.01403\n",
      "covet 0.01379\n",
      "deconstruct 0.01345\n",
      "\n",
      "[cz0ka4DuxPw] Joe Rogan Experience #1553 - Maynard James Keenan\n",
      "wine 0.03615\n",
      "omen 0.01919\n",
      "pasta 0.01802\n",
      "winemak 0.01431\n",
      "cbd 0.01405\n",
      "son-in-law 0.01399\n",
      "bcn 0.01295\n",
      "mead 0.01198\n",
      "arizona 0.01135\n",
      "muay 0.01133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf.print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    dist = lambda tfidf: np.sqrt(np.sum(tfidf * tfidf))\n",
    "    dot_prod = np.dot(a, b)\n",
    "    distances = dist(a) * dist(b)\n",
    "    return dot_prod / distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probably the dumbest way to do this\n",
    "tfidf_titles = [e.title for e in tfidf.scores.keys()]\n",
    "index_of_ep = lambda ep: tfidf_titles.index(ep.title)\n",
    "\n",
    "# (ep1, ep2), score\n",
    "cos_sim_matrix = np.zeros((len(episodes), len(episodes)), tuple)\n",
    "\n",
    "for a, b in tqdm([(a, b) for a in tfidf.scores for b in tfidf.scores]):\n",
    "    ai = index_of_ep(a)\n",
    "    bi = index_of_ep(b)\n",
    "    # Only fill half of the matrix\n",
    "    if bi > ai:\n",
    "        continue\n",
    "    cos_sim_matrix[ai][bi] = ((a, b), cosine_similarity(tfidf.scores[a], tfidf.scores[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cos_sim_matrix[:3]), len(cos_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_sim_list = []\n",
    "\n",
    "# Format as (index, index), similarity\n",
    "for row in cos_sim_matrix:\n",
    "    for item in row:\n",
    "        if item == 0: continue\n",
    "        (a, b), score = item\n",
    "        if a == b: continue\n",
    "        cos_sim_list.append((a, b, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Most similar podcast episodes\")\n",
    "print(\"=============================\\n\")\n",
    "cos_sim_list = sorted(cos_sim_list, key=lambda x: x[2], reverse=True)\n",
    "for a, b, score in cos_sim_list[:50]:\n",
    "    if a.is_main_episode and b.is_main_episode:\n",
    "        print(a)\n",
    "        print(b)\n",
    "        print(f\"\\t{round(score, 4) * 100}%\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_table = pd.DataFrame(\n",
    "    [(a.video_id, b.video_id, s) for a,b,s in cos_sim_list], \n",
    "    columns=[\"id1\", \"id2\", \"similarity\"],\n",
    ")\n",
    "cos_sim_table.to_csv(WEBSITE + \"cosine_similarity.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To protobufs\n",
    "63mb -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T19:40:37.363403Z",
     "start_time": "2020-11-23T19:40:37.196095Z"
    }
   },
   "outputs": [],
   "source": [
    "# protoc --python_out=./ ./episode-sim.proto\n",
    "# protoc --js_out=../../jre-vis/src/lib/proto ./episode-sim.proto\n",
    "import episode_sim_pb2 as ep_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T23:28:07.443556Z",
     "start_time": "2020-11-23T19:45:05.171492Z"
    }
   },
   "outputs": [],
   "source": [
    "cos_sim_table = pd.read_csv(WEBSITE + \"cosine_similarity.csv\")\n",
    "\n",
    "ids = cos_sim_table[\"id1\"].append(cos_sim_table[\"id2\"]).unique()\n",
    "IDs = ep_proto.IDs()\n",
    "for i, id in enumerate(ids):\n",
    "    row = IDs.rows.add()\n",
    "    row.idNum = i\n",
    "    row.id = id\n",
    "    \n",
    "epSims = ep_proto.EpisodeSims()\n",
    "for index, row in tqdm(cos_sim_table.iterrows()):\n",
    "    e = epSims.rows.add()\n",
    "    e.similarity = row[\"similarity\"]\n",
    "    e.idNum1 = [i for i, id in enumerate(ids) if id == row[\"id1\"]][0]\n",
    "    e.idNum2 = [i for i, id in enumerate(ids) if id == row[\"id2\"]][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T23:28:10.561962Z",
     "start_time": "2020-11-23T23:28:07.459080Z"
    }
   },
   "outputs": [],
   "source": [
    "PROTO_OUT = \"../../jre-vis/public/\"\n",
    "\n",
    "with open(PROTO_OUT + \"ep_sim\", \"wb\") as f:\n",
    "    f.write(epSims.SerializeToString())\n",
    "    \n",
    "with open(PROTO_OUT + \"ep_sim_id_lookup\", \"wb\") as f:\n",
    "    f.write(IDs.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFD Episodes in bins of 10 and by themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:24:30.618283Z",
     "start_time": "2020-11-18T04:24:19.783690Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num(e):\n",
    "    # TODO\n",
    "    # unsure why, but the tfidf ep #1564 and #1563 in the cfd\n",
    "    # are strings and not actual episodes\n",
    "    try:\n",
    "        x = e[0].number if e[0].number is not None else -1\n",
    "        return x\n",
    "    except Exception as x:\n",
    "        return -1\n",
    "    \n",
    "cfd_items = sorted(list(tfidf.cfd.items()), key=get_num, reverse=True)\n",
    "cfd_table = pd.DataFrame(\n",
    "    [(k.video_id, dict(v.most_common(400))) for k, v in cfd_items],\n",
    "    columns=[\"id\", \"top_words\"],\n",
    ")\n",
    "\n",
    "cfd_table.to_csv(WEBSITE + \"word_occurrences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Stem Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T20:32:51.959519Z",
     "start_time": "2020-11-25T20:32:48.944026Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_stem = {}\n",
    "for title, (cleaned, s2w) in cleaned_corpus:\n",
    "    reverse_stem.update(s2w)\n",
    "    \n",
    "rm_stem = lambda stem, w: w if len(stem) == len(w) else w[len(stem):]\n",
    "reverse_stem = {stem: [rm_stem(stem, w) for w in words] for stem, words in reverse_stem.items()}\n",
    "\n",
    "# Remove items with 1 element that is the exact same as the stem\n",
    "reverse_stem = {stem: words for stem, words in reverse_stem.items() if len(words) != 1 or words[0] != stem}\n",
    "\n",
    "# Remove words that are the exact same as the stem\n",
    "reverse_stem = {stem: [w for w in words if w != stem] for stem, words in reverse_stem.items()}\n",
    "    \n",
    "with open(WEBSITE + \"reverse_stem.json\", \"w\") as f:\n",
    "    f.write(json.dumps(reverse_stem))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
