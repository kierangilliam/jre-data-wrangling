{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:53:57.017788Z",
     "start_time": "2020-11-26T02:53:55.485921Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Video\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:53:57.024498Z",
     "start_time": "2020-11-26T02:53:57.020818Z"
    }
   },
   "outputs": [],
   "source": [
    "WEBSITE = \"../data/jre/website/\"\n",
    "# TODO How to estimate bandwidth for 2d data?\n",
    "BANDWIDTH = .1\n",
    "AVGS_LOCATION = \"averages_scale.25.0_color\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:53:57.040874Z",
     "start_time": "2020-11-26T02:53:57.033249Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_frame_from(ep, frame_no):\n",
    "    video_name = [v for v in video_files if ep.title in v][0]\n",
    "    cap = cv2.VideoCapture(video_name)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)    \n",
    "    plt.title(as_timestamp(frame_no, fps))\n",
    "    _, frame = cap.read()\n",
    "    plt.imshow(frame)\n",
    "    cap.release()\n",
    "    \n",
    "def as_timestamp(frame_no, fps):\n",
    "    sec = frame_no / fps\n",
    "    return f\"{floor(sec / 60 / 60)}:{floor(sec / 60) % 60}:{round(sec % 60, 1)}\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:53:58.227402Z",
     "start_time": "2020-11-26T02:53:57.044735Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.neighbors.kde module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth, KMeans, DBSCAN\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "def kde_cluster(Xdf, kernel=\"gaussian\", bandwidth=10, plot=False):\n",
    "    \"\"\"\n",
    "    Uses KDE to create clusters out of word vecs\n",
    "    \"\"\"\n",
    "    X = np.array(Xdf['x'])\n",
    "    X = X.reshape(-1, 1)\n",
    "\n",
    "    # TODO There is probably bias at the boundaries, should mirror X\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(X)\n",
    "    s = np.linspace(0, np.max(X)*1.5)\n",
    "    e = kde.score_samples(s.reshape(-1, 1))\n",
    "\n",
    "    # Reshape back to a 1 by N array\n",
    "    X = X.reshape(1, -1)\n",
    "\n",
    "    minima = argrelextrema(e, np.less)[0]\n",
    "    # Use the linspace to convert back into word indexes\n",
    "    minima = [s[m] for m in minima]\n",
    "    # (0, minima 1), (minima 1, minima 2), ... (minima n-1, minima n), (minima n, end)\n",
    "    minima_pairs = list(zip(np.insert(minima, 0, 0), np.append(minima, s[-1])))\n",
    "\n",
    "    clusters = [\n",
    "      np.unique(X[np.logical_and(X >= m1, X < m2)]) for m1, m2 in minima_pairs\n",
    "    ]\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(s, e)\n",
    "        plt.show()\n",
    "        print(f\"Number of clusters: {len(clusters)}\")\n",
    "        for c in clusters:\n",
    "            print(\"\\t\", len(c), np.unique([int(x) for x in c]))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "# Store frame numbers in the clusters instead of the average of the last frame\n",
    "def frame_idxs_clusters(avg_clusters, df):\n",
    "    df['cluster'] = np.full_like((len(avg_clusters)), -1)\n",
    "\n",
    "    for cluster_number, c in enumerate(avg_clusters):\n",
    "        cluster_cond = (df['x'] >= np.min(c)) & (df['x'] <= np.max(c))\n",
    "        df.loc[cluster_cond, 'cluster'] = cluster_number\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:54:06.711968Z",
     "start_time": "2020-11-26T02:53:58.230069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded episodes: 2455\n"
     ]
    }
   ],
   "source": [
    "CACHE = \"./jre-episodes.pickle\"\n",
    "\n",
    "with open(CACHE, \"rb\") as f:\n",
    "    episodes = pickle.load(f)\n",
    "\n",
    "print(f\"Number of loaded episodes: {len(episodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Averages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:54:07.293915Z",
     "start_time": "2020-11-26T02:54:06.714664Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "AVERAGES = f\"../data/jre/{AVGS_LOCATION}\"\n",
    "\n",
    "for file in os.listdir(AVERAGES):\n",
    "    matches = re.search(r\"-([A-Za-z0-9-_]*).npy\", file)\n",
    "    video_id = matches[1][-11:]\n",
    "    \n",
    "    try:\n",
    "        episode = [e for e in episodes if e.video_id == video_id][0]\n",
    "        episode.video_averages = np.load(\n",
    "            f\"{AVERAGES}/{file}\", allow_pickle=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Could not load video average data for \", video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T01:41:20.391212Z",
     "start_time": "2020-11-26T01:41:20.359299Z"
    }
   },
   "source": [
    "Main episodes vs main episodes with video averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:54:07.312620Z",
     "start_time": "2020-11-26T02:54:07.296333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1463, 49)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = [ep for ep in episodes if ep.video_averages is not None and ep.is_main_episode]\n",
    "len([ep for ep in episodes if ep.is_main_episode]), len(eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Clusters For Each Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:54:07.326964Z",
     "start_time": "2020-11-26T02:54:07.318144Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_frame_count(ep):\n",
    "    try:\n",
    "        video_name = [v for v in video_files if ep.title in v][0]\n",
    "    except IndexError as e:\n",
    "        print(\"Could not find video\", ep)\n",
    "        raise e\n",
    "\n",
    "    cap = cv2.VideoCapture(video_name)\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    return frames, fps\n",
    "\n",
    "def create_episode_clusters():\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    episode_clusters = []\n",
    "    for ep in tqdm(eps):\n",
    "        averages, total_frames = ep.video_averages\n",
    "        df = pd.DataFrame({\n",
    "          'x': averages,\n",
    "          'n': range(len(averages)),\n",
    "        })\n",
    "\n",
    "        avg_clusters = kde_cluster(df, bandwidth=BANDWIDTH, plot=False)\n",
    "        df = frame_idxs_clusters(avg_clusters, df)\n",
    "\n",
    "        clusters = {}\n",
    "        curr_cluster = df['cluster'][0]        \n",
    "        playhead_start = 0\n",
    "        skip_amount = total_frames / len(averages)\n",
    "        playhead = lambda cluster_idx: (cluster_idx * skip_amount) / total_frames\n",
    "        \n",
    "        for i, cluster_num in enumerate(df['cluster']):\n",
    "            if cluster_num != curr_cluster:\n",
    "                clusters[curr_cluster] = clusters.get(curr_cluster, []) + [(playhead_start, playhead(i - 1))]\n",
    "                playhead_start = playhead(i)\n",
    "                curr_cluster = cluster_num\n",
    "                \n",
    "        episode_clusters.append((ep, clusters))\n",
    "        \n",
    "    return episode_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:54:43.713194Z",
     "start_time": "2020-11-26T02:54:07.330621Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:36<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE = f\"./episode-clusters___{AVGS_LOCATION}.pkl\"\n",
    "# LOAD = True\n",
    "LOAD = False\n",
    "\n",
    "episode_clusters = []\n",
    "\n",
    "if LOAD:\n",
    "    with open(CACHE, \"rb\") as f:\n",
    "        episode_clusters = pickle.load(f)\n",
    "else:\n",
    "    episode_clusters = create_episode_clusters()\n",
    "    with open(CACHE, \"wb\") as f:\n",
    "        pickle.dump(episode_clusters, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate pie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:54:43.742433Z",
     "start_time": "2020-11-26T02:54:43.715690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pie_rows = []\n",
    "for ep, cluster_timestamps in episode_clusters:\n",
    "    data = {}\n",
    "    for i, t in cluster_timestamps.items():\n",
    "        data[i] = 0\n",
    "        for start, end in t:\n",
    "            data[i] += end - start\n",
    "\n",
    "    pie_rows.append([ep.video_id, dict(data)])\n",
    "            \n",
    "pie_data = pd.DataFrame(pie_rows, columns=[\"id\", \"data\"])\n",
    "pie_data.to_csv(WEBSITE + \"video_segments_high.csv\")\n",
    "len(pie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get pictures for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:09:06.437318Z",
     "start_time": "2020-11-26T03:08:41.416490Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 34/49 [00:17<00:08,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find video [xtwl-lu6goE] Joe Rogan Experience #643 - \"Big\" Jay Oakerson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:24<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "import imutils\n",
    "\n",
    "video_files = list(glob(\"/Volumes/JRE/jre-bucket/jre/videos/*.mp4\"))\n",
    "\n",
    "BLACK_AND_WHITE = True\n",
    "RESCALE_AMOUNT = .75\n",
    "\n",
    "def rescale_frame(frame, amount=.75):\n",
    "    width = int(frame.shape[1] * amount)\n",
    "    height = int(frame.shape[0] * amount)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "\n",
    "video_cluster_images = {}\n",
    "total = 0\n",
    "for ep, cluster_timestamps in tqdm(episode_clusters):\n",
    "    video_cluster_images[ep] = {}\n",
    "    \n",
    "    try:\n",
    "        video_name = [v for v in video_files if ep.title in v][0]\n",
    "    except IndexError as e:\n",
    "        print(\"Could not find video\", ep)\n",
    "        continue\n",
    "    \n",
    "    # Get a frame for the middle of each cluster timestamp\n",
    "    for i, t in cluster_timestamps.items():\n",
    "        cap = cv2.VideoCapture(video_name)\n",
    "        frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "       \n",
    "        # Get the segment in the cluster with the longest time on that shot\n",
    "        start, end = t[np.argmax([e - s for s, e in t])]\n",
    "        middle = (end - start) / 2 + start\n",
    "        # Don't get pictures for items with less than 1% of the total time\n",
    "        if end - start < .01:            \n",
    "            continue\n",
    "        total += 1\n",
    "        \n",
    "        # Read frame        \n",
    "        frame_no = int(frames * middle)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n",
    "        \n",
    "        averages, _ = ep.video_averages\n",
    "#         print(\"CLUSTER\", i)\n",
    "#         print(\"Frames: \", frames)\n",
    "#         print(\"Fps\", fps)\n",
    "#         print(\"Start\", start, \"end\", end)\n",
    "#         print(\"Frame no\", frame_no)        \n",
    "#         print(middle)\n",
    "#         print(as_timestamp(int(frames * start), fps), \n",
    "#               as_timestamp(frame_no, fps), \n",
    "#               as_timestamp(int(frames * end), fps))\n",
    "        \n",
    "        ret, frame = cap.read()                \n",
    "\n",
    "        frame = rescale_frame(frame, amount=RESCALE_AMOUNT)\n",
    "        if BLACK_AND_WHITE: frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        video_cluster_images[ep][i] = {'frame':frame, 'frame_no':frame_no, 'frames':frames, 'fps':fps}        \n",
    "        \n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:55:08.637383Z",
     "start_time": "2020-11-26T02:55:08.633156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_cluster_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:58:35.925021Z",
     "start_time": "2020-11-26T02:58:35.920984Z"
    }
   },
   "source": [
    "## Save Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:09:06.682367Z",
     "start_time": "2020-11-26T03:09:06.442558Z"
    }
   },
   "outputs": [],
   "source": [
    "for ep, clusters in video_cluster_images.items():\n",
    "    for cluster_n, image in clusters.items():\n",
    "        cv2.imwrite(f\"{WEBSITE}/images/{ep.video_id}.cluster.{cluster_n}.jpg\", image['frame'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:56:22.619118Z",
     "start_time": "2020-11-26T02:56:07.019722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25134e561df486e89323eb31a87aa65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303c34f6f31247338bf85a7caafeac7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, max=48)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e716105446f745fe8f1f6f427635285b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Cluster:', options=(4, 5), value=4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider, Dropdown\n",
    "%matplotlib inline\n",
    "from ipywidgets.widgets.interaction import show_inline_matplotlib_plots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def show_video_segments():\n",
    "    def get_title(ep, cluster, timestamp):\n",
    "        try:\n",
    "            percentage = pie_data.loc[pie_data['id'] == ep.video_id]['data'].iloc[0][cluster]\n",
    "        except Exception as e:\n",
    "            percentage = 0\n",
    "            print(\"Could not get percentage for\", ep.number)\n",
    "        return f\"{ep.title} -- {cluster} ({round(percentage * 100)}%, {timestamp})\"\n",
    "    \n",
    "    cluster = choose_cluster.value        \n",
    "    ep, cluster_images = list(video_cluster_images.items())[ep_slider.value]\n",
    "    img = cluster_images[cluster]\n",
    "    \n",
    "    averages = ep.video_averages[0]\n",
    "    df = pd.DataFrame({ 'x': averages, 'n': range(len(averages))})\n",
    "    avg_clusters = kde_cluster(df, bandwidth=BANDWIDTH, plot=False)\n",
    "    df = frame_idxs_clusters(avg_clusters, df)\n",
    "    df['color'] = np.where(df['cluster'] == cluster, 'green', 'black')\n",
    "\n",
    "    with out:\n",
    "        clear_output()                \n",
    "        fig, (img_ax, clus_ax) = plt.subplots(2)\n",
    "        fig.suptitle(get_title(ep, cluster, as_timestamp(img['frame_no'], img['fps'])))        \n",
    "        \n",
    "        # Show frame image\n",
    "        if BLACK_AND_WHITE: img_ax.imshow(img['frame'], cmap='gray')\n",
    "        else: img_ax.imshow(img['frame'])\n",
    "\n",
    "        # Show scatter plot of clusters\n",
    "        # Highlight the frame that was used as orange\n",
    "        clus_ax.scatter(df['x'], y=df['n'], c=df['color'])        \n",
    "        cluster_frame = int(img['frame_no'] / img['frames'] * len(df['color']))\n",
    "        clus_ax.scatter(df.loc[cluster_frame, 'x'], y=df.loc[cluster_frame, 'n'], c='orange')\n",
    "\n",
    "        show_inline_matplotlib_plots()\n",
    "        \n",
    "    \n",
    "def on_cluster_change(change):\n",
    "    show_video_segments()\n",
    "    \n",
    "def on_ep_change(change):\n",
    "    new_x = change['new']\n",
    "    ep, clusters = list(video_cluster_images.items())[new_x]\n",
    "    choose_cluster.options = clusters.keys()\n",
    "    choose_cluster.value = list(clusters.keys())[0]    \n",
    "    show_video_segments()\n",
    "\n",
    "initial_ep = 0\n",
    "\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "    \n",
    "choose_cluster = Dropdown(description='Cluster:')\n",
    "choose_cluster.observe(on_cluster_change, names='value')\n",
    "\n",
    "ep_slider = IntSlider(min=0, max=len(video_cluster_images) - 1)\n",
    "ep_slider.observe(on_ep_change, names='value')\n",
    "ep_slider.value = initial_ep\n",
    "on_ep_change({'new': initial_ep})\n",
    "\n",
    "display(ep_slider, choose_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful for checking out output of kde \n",
    "...With different values for the bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T02:57:53.659937Z",
     "start_time": "2020-11-26T02:57:43.329328Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1124ae306a5d4a828cdc26ac594cfb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='x', max=48), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_frame_averages(x)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from ipywidgets import interact, IntSlider\n",
    "py.offline.init_notebook_mode(connected = True)\n",
    "\n",
    "bandwidth = BANDWIDTH\n",
    "bandwidth = .1\n",
    "frame_no = 4592\n",
    "\n",
    "def show_frame_from(ep, frame_no):\n",
    "    video_name = [v for v in video_files if ep.video_id in v][0]\n",
    "    cap = cv2.VideoCapture(video_name)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)    \n",
    "    plt.title(as_timestamp(frame_no, fps))\n",
    "    _, frame = cap.read()\n",
    "    plt.imshow(frame)\n",
    "    cap.release()\n",
    "\n",
    "def show_frame_averages(x):\n",
    "    df = pd.DataFrame({\n",
    "      'x': eps[x].video_averages[0],\n",
    "      'n': range(len(eps[x].video_averages[0])),\n",
    "    })\n",
    "    \n",
    "    avg_clusters = kde_cluster(df, plot=False, bandwidth=bandwidth)\n",
    "\n",
    "    df = frame_idxs_clusters(avg_clusters, df)\n",
    "    # For a discrete color scale\n",
    "    df['cluster'] = df['cluster'].astype(str)\n",
    "    \n",
    "    show_frame_from(ep, frame_no)\n",
    "\n",
    "    title = f\"{str(eps[x])} {len(df['x'])}\"\n",
    "    fig = px.scatter(df, x='x', color='cluster', title=title)\n",
    "    fig.show()\n",
    "        \n",
    "\n",
    "interact(show_frame_averages, x=IntSlider(value=5, min=0, max=len(eps) - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
