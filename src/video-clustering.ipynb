{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:51:14.761593Z",
     "start_time": "2020-11-17T19:51:14.752910Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Video\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:42:51.968314Z",
     "start_time": "2020-11-17T21:42:51.962433Z"
    }
   },
   "outputs": [],
   "source": [
    "WEBSITE = \"../data/jre/website/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:51:14.782150Z",
     "start_time": "2020-11-17T19:51:14.763861Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth, KMeans, DBSCAN\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "def kde_cluster(Xdf, kernel=\"gaussian\", bandwidth=10, plot=False):\n",
    "    \"\"\"\n",
    "    Uses KDE to create clusters out of word vecs\n",
    "    \"\"\"\n",
    "    X = np.array(Xdf['x'])\n",
    "    X = X.reshape(-1, 1)\n",
    "\n",
    "    # TODO There is probably bias at the boundaries, should mirror X\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(X)\n",
    "    s = np.linspace(0, np.max(X)*1.5)\n",
    "    e = kde.score_samples(s.reshape(-1, 1))\n",
    "\n",
    "    # Reshape back to a 1 by N array\n",
    "    X = X.reshape(1, -1)\n",
    "\n",
    "    minima = argrelextrema(e, np.less)[0]\n",
    "    # Use the linspace to convert back into word indexes\n",
    "    minima = [s[m] for m in minima]\n",
    "    # (0, minima 1), (minima 1, minima 2), ... (minima n-1, minima n), (minima n, end)\n",
    "    minima_pairs = list(zip(np.insert(minima, 0, 0), np.append(minima, s[-1])))\n",
    "\n",
    "    clusters = [\n",
    "      np.unique(X[np.logical_and(X >= m1, X < m2)]) for m1, m2 in minima_pairs\n",
    "    ]\n",
    "\n",
    "    if plot:\n",
    "      plt.plot(s, e)\n",
    "      plt.show()\n",
    "      print(f\"Number of clusters: {len(clusters)}\")\n",
    "      for c in clusters:\n",
    "          print(\"\\t\", len(c), np.unique([int(x) for x in c]))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "# Store frame numbers in the clusters instead of the average of the last frame\n",
    "def frame_idxs_clusters(avg_clusters, df):\n",
    "    df['cluster'] = np.full_like((len(avg_clusters)), -1)\n",
    "\n",
    "    for cluster_number, c in enumerate(avg_clusters):\n",
    "        for frame_number, frame in enumerate(df['x']):\n",
    "            if df['x'][frame_number] >= np.min(c) and df['x'][frame_number] <= np.max(c):\n",
    "                df['cluster'][frame_number] = cluster_number\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:51:30.764991Z",
     "start_time": "2020-11-17T19:51:14.785315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded episodes: 2455\n"
     ]
    }
   ],
   "source": [
    "CACHE = \"./jre-episodes.pickle\"\n",
    "\n",
    "with open(CACHE, \"rb\") as f:\n",
    "    episodes = pickle.load(f)\n",
    "\n",
    "print(f\"Number of loaded episodes: {len(episodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:51:31.115319Z",
     "start_time": "2020-11-17T19:51:30.767353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1463, 1373)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main episodes vs main episodes with video averages\n",
    "eps = [ep for ep in episodes if ep.video_averages is not None and ep.is_main_episode]\n",
    "len([ep for ep in episodes if ep.is_main_episode]), len(eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:51:31.120621Z",
     "start_time": "2020-11-17T19:51:31.117428Z"
    }
   },
   "outputs": [],
   "source": [
    "averages, total_frames = eps[0].video_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:51:31.126161Z",
     "start_time": "2020-11-17T19:51:31.122547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12639, 239820)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(averages), total_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:51:31.359885Z",
     "start_time": "2020-11-17T19:51:31.127764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71217fac652346d799a7a22aed52ee5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=402, description='x', max=1372), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_frame_averages(x)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "def show_frame_averages(x):\n",
    "    df = pd.DataFrame({\n",
    "      'x': eps[x].video_averages[0],\n",
    "      'n': range(len(eps[x].video_averages[0])),\n",
    "    })\n",
    "    fig = px.scatter(df, x='x', color='n', title=str(eps[x]))\n",
    "    fig.show()\n",
    "\n",
    "interact(show_frame_averages, x=IntSlider(value=402, min=0, max=len(eps) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:51:35.500103Z",
     "start_time": "2020-11-17T19:51:31.362840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76af3f81285a4db9be3c99648b9cea7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=215, description='x', max=1372), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_frame_averages(x)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO How to estimate bandwidth for 2d data?\n",
    "BANDWIDTH = 1\n",
    "\n",
    "from ipywidgets import interact, IntSlider\n",
    "def show_frame_averages(x):\n",
    "    df = pd.DataFrame({\n",
    "      'x': eps[x].video_averages[0],\n",
    "      'n': range(len(eps[x].video_averages[0])),\n",
    "    })\n",
    "    avg_clusters = kde_cluster(df, plot=True, bandwidth=BANDWIDTH)\n",
    "\n",
    "    df = frame_idxs_clusters(avg_clusters, df)\n",
    "    # For a discrete color scale\n",
    "    df['cluster'] = df['cluster'].astype(str)\n",
    "    \n",
    "    fig = px.scatter(df, x='x', color='cluster', title=str(eps[x]))\n",
    "    fig.show()\n",
    "\n",
    "interact(show_frame_averages, x=IntSlider(value=215, min=0, max=len(eps) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Clusters For Each Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T20:56:45.338929Z",
     "start_time": "2020-11-17T19:51:35.502686Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "SKIP_DIVIS = 30 // 2 \n",
    "\n",
    "episode_clusters = []\n",
    "for ep in tqdm(eps):\n",
    "    averages, total_frames = ep.video_averages\n",
    "    df = pd.DataFrame({\n",
    "      'x': averages,\n",
    "      'n': range(len(averages)),\n",
    "    })\n",
    "    \n",
    "    avg_clusters = kde_cluster(df, bandwidth=BANDWIDTH, plot=False)\n",
    "    df = frame_idxs_clusters(avg_clusters, df)\n",
    "    \n",
    "    curr_cluster = 0\n",
    "    clusters = {}\n",
    "    prog_start = 0\n",
    "    for i, cluster_num in enumerate(df['cluster']):\n",
    "        progress = SKIP_DIVIS * i / total_frames\n",
    "        if cluster_num != curr_cluster:\n",
    "            arr = clusters.get(curr_cluster, [])\n",
    "            arr.append((prog_start, progress))\n",
    "            clusters[curr_cluster] = arr\n",
    "            \n",
    "            prog_start = progress\n",
    "            curr_cluster = cluster_num\n",
    "            \n",
    "    episode_clusters.append((ep, clusters))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:27:58.298670Z",
     "start_time": "2020-11-17T21:27:44.353036Z"
    }
   },
   "outputs": [],
   "source": [
    "CACHE = \"./epside-clusters-cache.pkl\"\n",
    "with open(CACHE, \"wb\") as f:\n",
    "    pickle.dump(episode_clusters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:43:08.474619Z",
     "start_time": "2020-11-17T21:43:08.450958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate pie data\n",
    "\n",
    "pie_rows = []\n",
    "for ep, cluster_timestamps in episode_clusters[:5]:\n",
    "    data = {}\n",
    "    for i, t in cluster_timestamps.items():\n",
    "        data[i] = 0\n",
    "        for start, end in t:\n",
    "            data[i] += end - start\n",
    "\n",
    "    pie_rows.append([ep.video_id, ep.title, ep.number, dict(data)])\n",
    "            \n",
    "pie_data = pd.DataFrame(pie_rows, columns=[\"id\", \"title\", \"number\", \"data\"])\n",
    "pie_data.to_csv(WEBSITE + \"video_segments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:47:48.817247Z",
     "start_time": "2020-11-17T21:47:48.807874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10483"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GET PICTURES FOR EACH CLUSTER\n",
    "\n",
    "total = 0\n",
    "for ep, cluster_timestamps in episode_clusters:\n",
    "    # Get a frame for the middle of each cluster timestamp\n",
    "    for i, t in cluster_timestamps.items():\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
